{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modeling using corextopic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihirsakaria/solving-maths-problems-in-hindi/blob/main/Topic_Modeling_Using_Corextopic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzOYU_yy2EDg",
        "outputId": "0d13a379-a7d2-46cf-b581-f80fc4d49d02"
      },
      "source": [
        "!pip install corextopic"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting corextopic\n",
            "  Downloading corextopic-1.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: corextopic\n",
            "Successfully installed corextopic-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFvWXWuu1GZ4"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as ss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import corextopic.corextopic as ct\n",
        "import corextopic.vis_topic as vt # jupyter notebooks will complain matplotlib is being loaded twice\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import csr_matrix\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l7f4b-kp_AO",
        "outputId": "d725d549-cf2c-4242-d73a-f667dc7cb266"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvof0x7Xqx6Q"
      },
      "source": [
        "def create_stopwords():\n",
        "  stopwords_df = pd.read_csv('/content/drive/MyDrive/Maths Problem Solving BTP/Hindi_Stopwords.csv')\n",
        "  temp_list = stopwords_df.values.tolist()\n",
        "  stopwords_list = []\n",
        "  for i in temp_list:\n",
        "    stopword = i[0]\n",
        "    stopwords_list.append(stopword)\n",
        "  return stopwords_list"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ZOwpipq1Aw"
      },
      "source": [
        "def wordTokenize(text):\n",
        "  return text.split(\" \")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ff7sq3-q-bh"
      },
      "source": [
        "#Tokenising a text, removing stopwords and cleaning it\n",
        "def clean_text_initial(text):\n",
        "    text = \"\".join(text.split(\".\"))\n",
        "    text = \"\".join(text.split(\"।\"))\n",
        "    text = \"\".join(text.split(\"?\"))\n",
        "    \n",
        "    text = \"\".join(text.split(\"/\"))\n",
        "    text = \" \".join(text.split())\n",
        "    text = ' '.join([x.lower() for x in wordTokenize(text) if x.lower() not in unwanted_list])\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urRdruaocJmK"
      },
      "source": [
        "\n",
        "def create_vocab(train):\n",
        "  unique_words = set()\n",
        "  for text in train:\n",
        "    tokens = wordTokenize(text)\n",
        "    for token in tokens:\n",
        "      unique_words.add(token)\n",
        "  vocab = {}\n",
        "  for index, word in enumerate(list(unique_words)):\n",
        "    vocab[word] = index\n",
        "  return vocab\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDauFDgRdbWm"
      },
      "source": [
        "def Vectorization(train):\n",
        "  vocab = create_vocab(train)\n",
        "  # print(vocab)\n",
        "  row, col, val = [], [], []\n",
        "  for idx, sentence in enumerate(train):\n",
        "    count_word = {}\n",
        "    tokens = wordTokenize(sentence)\n",
        "    for token in tokens:\n",
        "      count_word[token] = sentence.count(token)\n",
        "    for word, count in count_word.items():\n",
        "      col_index = vocab.get(word)\n",
        "      if col_index >=0:\n",
        "        row.append(idx)\n",
        "        col.append(col_index)\n",
        "        val.append(count)\n",
        "  return csr_matrix((val, (row, col)), shape = (len(train), len(vocab)))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Ig3ZslfGJ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMnzQ4Eg247h",
        "outputId": "401d2802-c58d-4ff7-e462-7c68866a37f7"
      },
      "source": [
        "\n",
        "df1=pd.read_csv(\"/content/drive/MyDrive/Maths Problem Solving BTP/Hindi_Datasets.csv\")\n",
        "\n",
        "train = df1['Problem']\n",
        "unwanted_list = create_stopwords()\n",
        "train = train.apply(clean_text_initial)\n",
        "\n",
        "words = create_vocab(train)\n",
        "Words = list(words.keys())\n",
        "\n",
        "vectors = Vectorization(train)\n",
        "print(vectors.shape)\n",
        "print(len(Words))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(446, 1741)\n",
            "1741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDn1pQ9w6CYI",
        "outputId": "4ed5f5ed-5514-43e2-c6a5-f85dbb36073f"
      },
      "source": [
        "anchor_words = [['संख्या' ,'प्रायिकता','संभावना','बांटा','यादृच्छिक','संभावित','संयोजनों','क्रम']]\n",
        "# anchor_words2 = [['संख्या' ,'प्रायिकता','संभावना','बांटा','यादृच्छिक','संभावित','संयोजनों','क्रम','कितने','गणना','अपेक्षित','तरीकों','मूल्य']]\n",
        "anchored_topic_model = ct.Corex(n_hidden=2, seed=2)\n",
        "anchored_topic_model.fit(vectors, words = Words, anchors=anchor_words, anchor_strength=6);\n",
        "\n",
        "for n in range(len(anchor_words)):\n",
        "    topic_words,_,_ = zip(*anchored_topic_model.get_topics(topic=n))\n",
        "    print('{}: '.format(n) + ', '.join(topic_words))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: प्रायिकता, संख्या, यादृच्छिक, संभावना, क्या, रूप, व्यक्त, उभयनिष्ठ, उत्तर, भिन्न\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQpIWgFdKmdn",
        "outputId": "e4402800-6c9c-4957-caa5-cbec337914a9"
      },
      "source": [
        "result = anchored_topic_model.predict(vectors)\n",
        "print(type(result))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYkkdV-Oq2Ep",
        "outputId": "ef017e3e-90c7-41b4-a6ed-43ecb728556f"
      },
      "source": [
        "arithmatic = 0\n",
        "prob = 0\n",
        "false = 0\n",
        "for i in range(len(result)):\n",
        "  if i<215:\n",
        "    if result[i][1] == True:\n",
        "      arithmatic +=1\n",
        "    if result[i][0] == True:\n",
        "      false +=1\n",
        "  else:\n",
        "    if result[i][0] == True:\n",
        "      prob +=1\n",
        "    if(result[i][1] == True):\n",
        "      false+=1\n",
        "print(arithmatic)\n",
        "print(prob)\n",
        "print(false)\n",
        "print(len(result))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "123\n",
            "81\n",
            "446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBiFvhkn8izs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}